import os
import torch
import argparse
from tqdm import tqdm
from torchvision.utils import save_image

# Ajuste as importa√ß√µes conforme a estrutura do seu projeto
from models.unet import UNet
from diffusion.ddpm import Diffusion

def generate_images(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Iniciando gera√ß√£o no dispositivo: {device}")

    # 1. Configura a Pasta de Sa√≠da
    output_dir = os.path.join("fid_samples", args.run_name)
    os.makedirs(output_dir, exist_ok=True)

    # 2. Inicializa o Modelo e a Difus√£o
    model = UNet(image_size=args.image_size).to(device)
    diffusion = Diffusion(img_size=args.image_size, device=device)

    # 3. Carrega OBRIGATORIAMENTE o modelo EMA do Checkpoint
    ckpt_path = os.path.join("models", args.run_name, "ckpt.pt")
    if not os.path.exists(ckpt_path):
        raise FileNotFoundError(f"Checkpoint n√£o encontrado em {ckpt_path}")
    
    checkpoint = torch.load(ckpt_path, map_location=device)
    
    if 'ema_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['ema_state_dict'])
        print("‚úÖ Pesos do modelo EMA carregados com sucesso!")
    else:
        print("‚ö†Ô∏è AVISO: ema_state_dict n√£o encontrado. Usando pesos normais.")
        model.load_state_dict(checkpoint['model_state_dict'])
    
    model.eval()

    # 4. Loop de Gera√ß√£o Inteligente
    images_left = args.num_images
    total_generated = 0

    print(f"\nGerando um total de {args.num_images} imagens...")
    
    with torch.no_grad():
        with tqdm(total=args.num_images, desc="Gerando") as pbar:
            while images_left > 0:
                # Garante que o √∫ltimo batch n√£o gere imagens a mais
                current_batch_size = min(args.batch_size, images_left)

                # ==============================================================
                # üîÑ ESCOLHA O M√âTODO DE GERA√á√ÉO (Comente/Descomente aqui)
                # ==============================================================

                # --- OP√á√ÉO 1: DDPM (Artigo Original, 1000 passos, Lento) ---
                # sampled_images = diffusion.sample(model, n=current_batch_size)
                # # Corre√ß√£o obrigat√≥ria: desnormaliza de [-1, 1] para [0, 1]
                # sampled_images = (sampled_images.clamp(-1, 1) + 1) / 2.0 
                
                # --- OP√á√ÉO 2: DDIM (R√°pido, 50 passos) ---
                sampled_images = diffusion.sample_ddim(model, n=current_batch_size, ddim_timesteps=50, ddim_eta=0.0)
                # Nota: N√£o precisa de corre√ß√£o aqui, pois nosso sample_ddim j√° devolve [0, 1]!

                # ==============================================================

                # Salva cada imagem do batch individualmente
                for j in range(current_batch_size):
                    img_idx = total_generated + j
                    save_image(sampled_images[j], os.path.join(output_dir, f"img_{img_idx:05d}.png"))
                
                total_generated += current_batch_size
                images_left -= current_batch_size
                pbar.update(current_batch_size)

    print(f"\nüéâ Gera√ß√£o conclu√≠da! {total_generated} imagens salvas em: {output_dir}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--run_name', type=str, required=True, help="Nome da pasta do modelo treinado")
    parser.add_argument('--image_size', type=int, default=32, help="Tamanho da imagem")
    parser.add_argument('--batch_size', type=int, default=128, help="Imagens geradas por vez na GPU")
    parser.add_argument('--num_images', type=int, default=50000, help="Total de imagens para gerar")
    args = parser.parse_args()
    
    generate_images(args)