"""
FID Score Calculator para DDPM
Calcula o Fr√©chet Inception Distance entre imagens geradas e dataset real
"""

import torch
import torchvision
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
import argparse
from scipy import linalg
from PIL import Image
import os

# Importa seus m√≥dulos (CORRIGIDO PARA UNet MAI√öSCULO)
from models.unet import UNet
from diffusion.ddpm import Diffusion

class InceptionV3FeatureExtractor:
    """Extrai features usando InceptionV3 para c√°lculo de FID"""
    
    def __init__(self, device='cuda'):
        self.device = device
        
        # Carrega InceptionV3 pr√©-treinado
        print("üì• Carregando InceptionV3...")
        # Adicionado weights=... para evitar warnings de deprecia√ß√£o do torchvision moderno
        weights = torchvision.models.Inception_V3_Weights.DEFAULT
        inception = torchvision.models.inception_v3(weights=weights, transform_input=False)
        inception.fc = torch.nn.Identity()  # Remove √∫ltima camada
        inception.eval()
        self.model = inception.to(device)
        
        # Freeze todos os par√¢metros
        for param in self.model.parameters():
            param.requires_grad = False
            
        print("‚úÖ InceptionV3 carregado!")
    
    def preprocess(self, images):
        """
        Preprocessa imagens para InceptionV3
        Input: Tensor (B, 3, H, W) com valores em [-1, 1]
        Output: Tensor (B, 3, 299, 299) com valores normalizados para ImageNet
        """
        # De [-1, 1] para [0, 1]
        images = (images + 1) / 2
        
        # Clamp para garantir
        images = torch.clamp(images, 0, 1)
        
        # Resize para 299x299 (tamanho esperado pelo Inception)
        if images.shape[-1] != 299:
            images = torch.nn.functional.interpolate(
                images, size=(299, 299), mode='bilinear', align_corners=False
            )
        
        # Normaliza com stats do ImageNet
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(images.device)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(images.device)
        images = (images - mean) / std
        
        return images
    
    def extract_features(self, images):
        """Extrai features de um batch de imagens"""
        with torch.no_grad():
            images = self.preprocess(images)
            features = self.model(images)
        return features.cpu().numpy()

def calculate_fid_statistics(features):
    """Calcula m√©dia e covari√¢ncia das features"""
    mu = np.mean(features, axis=0)
    sigma = np.cov(features, rowvar=False)
    return mu, sigma

def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):
    """Calcula a dist√¢ncia de Fr√©chet entre duas gaussianas multivariadas"""
    mu1 = np.atleast_1d(mu1)
    mu2 = np.atleast_1d(mu2)
    
    sigma1 = np.atleast_2d(sigma1)
    sigma2 = np.atleast_2d(sigma2)
    
    diff = mu1 - mu2
    
    # Produto pode ser quase singular
    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
    
    if not np.isfinite(covmean).all():
        print("‚ö†Ô∏è Covari√¢ncia cont√©m valores n√£o-finitos. Adicionando epsilon √† diagonal.")
        offset = np.eye(sigma1.shape[0]) * eps
        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))
    
    # Erro num√©rico pode dar uma leve parte imagin√°ria
    if np.iscomplexobj(covmean):
        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):
            m = np.max(np.abs(covmean.imag))
            raise ValueError(f"Parte imagin√°ria muito grande: {m}")
        covmean = covmean.real
    
    tr_covmean = np.trace(covmean)
    fid = diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean
    return fid

def get_real_dataset_features(extractor, num_samples=10000, batch_size=64, dataset_path='./cifar10_data'):
    """Extrai features do dataset real (CIFAR-10)"""
    print(f"\nüìä Extraindo features do dataset real ({num_samples} imagens)...")
    
    transform = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    dataset = torchvision.datasets.CIFAR10(
        root=dataset_path, train=True, download=True, transform=transform
    )
    
    if num_samples < len(dataset):
        indices = np.random.choice(len(dataset), num_samples, replace=False)
        dataset = torch.utils.data.Subset(dataset, indices)
    
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)
    all_features = []
    
    for images, _ in tqdm(dataloader, desc="Extraindo features reais"):
        images = images.to(extractor.device)
        features = extractor.extract_features(images)
        all_features.append(features)
    
    all_features = np.concatenate(all_features, axis=0)
    print(f"‚úÖ Features reais extra√≠das: {all_features.shape}")
    return all_features

def generate_and_extract_features(model, diffusion, extractor, num_samples=10000, batch_size=64):
    """Gera imagens com o modelo e extrai features"""
    print(f"\nüé® Gerando {num_samples} imagens e extraindo features (ISSO VAI DEMORAR)...")
    
    all_features = []
    num_batches = (num_samples + batch_size - 1) // batch_size
    
    for i in range(num_batches):
        print(f"\n‚è≥ Batch {i+1}/{num_batches} (Tamanho: {batch_size})")
        current_batch_size = min(batch_size, num_samples - i * batch_size)
        
        with torch.no_grad():
            generated_images = diffusion.sample(model, n=current_batch_size)
        
        features = extractor.extract_features(generated_images)
        all_features.append(features)
    
    all_features = np.concatenate(all_features, axis=0)
    print(f"\n‚úÖ Features geradas extra√≠das: {all_features.shape}")
    return all_features

def calculate_fid(args):
    """Fun√ß√£o principal para calcular FID"""
    device = args.device
    
    print("\n" + "="*70)
    print("üìä CALCULANDO FID SCORE")
    print("="*70)
    print(f"üì¶ Checkpoint: {args.checkpoint}")
    print(f"üéØ Amostras: {args.num_samples}")
    print(f"üìè Batch Size: {args.batch_size}")
    print(f"üíª Device: {device}")
    print("="*70 + "\n")
    
    # 1. Carrega o modelo (CORRIGIDO)
    print("üîß Carregando modelo...")
    model = UNet(image_size=args.image_size).to(device)
    diffusion = Diffusion(img_size=args.image_size, device=device)
    
    checkpoint = torch.load(args.checkpoint, map_location=device)
    
    # L√≥gica de carregamento do EMA
    if 'ema_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['ema_state_dict'])
        print("‚úÖ Modelo EMA carregado (Melhor qualidade)!")
    elif 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print("‚úÖ Modelo padr√£o carregado!")
    else:
        model.load_state_dict(checkpoint)
        print("‚úÖ Modelo carregado (checkpoint direto)!")
    
    model.eval()
    
    # 2. Inicializa extrator
    extractor = InceptionV3FeatureExtractor(device=device)
    
    # 3. Features reais (Com cache)
    if os.path.exists(args.real_features_cache):
        print(f"\nüì• Carregando features reais do cache: {args.real_features_cache}")
        cache = np.load(args.real_features_cache)
        real_features = cache['features']
    else:
        real_features = get_real_dataset_features(
            extractor, num_samples=args.num_samples, batch_size=args.batch_size, dataset_path=args.dataset_path
        )
        print(f"üíæ Salvando cache de features reais...")
        np.savez_compressed(args.real_features_cache, features=real_features)
    
    # 4. Gera imagens e extrai features
    generated_features = generate_and_extract_features(
        model, diffusion, extractor, num_samples=args.num_samples, batch_size=args.batch_size
    )
    
    # 5 & 6. Calcula estat√≠sticas e FID
    print("\nüìà Calculando estat√≠sticas e Dist√¢ncia de Fr√©chet...")
    mu_real, sigma_real = calculate_fid_statistics(real_features)
    mu_gen, sigma_gen = calculate_fid_statistics(generated_features)
    fid_score = calculate_frechet_distance(mu_real, sigma_real, mu_gen, sigma_gen)
    
    # 7. Resultados
    print("\n" + "="*70)
    print(f"üéâ FID Score: {fid_score:.2f}")
    print("="*70)
    
    if fid_score < 10: print("üåü EXCELENTE! Qualidade state-of-the-art")
    elif fid_score < 30: print("‚úÖ MUITO BOM! Qualidade alta")
    elif fid_score < 50: print("üëç BOM! Modelo est√° aprendendo bem")
    elif fid_score < 100: print("‚ö†Ô∏è  RAZO√ÅVEL. Precisa de mais treino")
    else: print("‚ùå RUIM. Modelo precisa de ajustes")
    
    return fid_score

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoint', type=str, required=True, help='Caminho do checkpoint (.pt)')
    parser.add_argument('--num_samples', type=int, default=10000, help='N√∫mero de amostras')
    parser.add_argument('--batch_size', type=int, default=256, help='Batch size (256 cabe tranquilo na RTX A4500)')
    parser.add_argument('--image_size', type=int, default=32, help='Tamanho da imagem')
    parser.add_argument('--device', type=str, default='cuda', help='Device')
    parser.add_argument('--dataset_path', type=str, default='./cifar10_data', help='Caminho do CIFAR')
    parser.add_argument('--real_features_cache', type=str, default='cifar10_real_features.npz')
    
    args = parser.parse_args()
    calculate_fid(args)